{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport tensorflow as tf\n\n\nimport tensorflow_datasets as tfds\nimdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"5687da5f-cbf2-4da5-9948-485a0c7853c6","_cell_guid":"5ca7927c-6eaa-4eac-8d8a-8a7639747b01","trusted":true},"cell_type":"code","source":"import numpy as np\n\ntrain_data, test_data = imdb['train'], imdb['test']\n\ntraining_sentences = []\ntraining_labels = []\n\ntesting_sentences = []\ntesting_labels = []\n\n\nfor s,l in train_data:\n  training_sentences.append(str(s.numpy()))\n  training_labels.append(l.numpy())\n  \nfor s,l in test_data:\n  testing_sentences.append(str(s.numpy()))\n  testing_labels.append(l.numpy())\n  \ntraining_labels_final = np.array(training_labels)\ntesting_labels_final = np.array(testing_labels)\n\n\n\ntraining_sentences[0]\n\n\ntraining_labels[0]\n\n\nvocab_size = 10000\nembedding_dim = 16\nmax_length = 120\ntrunc_type='post'\noov_tok = \"<OOV>\"\n\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\nword_index = tokenizer.word_index\nsequences = tokenizer.texts_to_sequences(training_sentences)\npadded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences,maxlen=max_length)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(6, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()\n\n","execution_count":16,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 120, 16)           160000    \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 1920)              0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 6)                 11526     \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 171,533\nTrainable params: 171,533\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nhistory = model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))","execution_count":17,"outputs":[{"output_type":"stream","text":"Train on 25000 samples, validate on 25000 samples\nEpoch 1/10\n25000/25000 [==============================] - 7s 279us/sample - loss: 0.4851 - accuracy: 0.7530 - val_loss: 0.3460 - val_accuracy: 0.8496\nEpoch 2/10\n25000/25000 [==============================] - 6s 260us/sample - loss: 0.2395 - accuracy: 0.9073 - val_loss: 0.3701 - val_accuracy: 0.8394\nEpoch 3/10\n25000/25000 [==============================] - 6s 255us/sample - loss: 0.0928 - accuracy: 0.9754 - val_loss: 0.4493 - val_accuracy: 0.8282\nEpoch 4/10\n25000/25000 [==============================] - 6s 249us/sample - loss: 0.0221 - accuracy: 0.9974 - val_loss: 0.5352 - val_accuracy: 0.8260\nEpoch 5/10\n25000/25000 [==============================] - 6s 259us/sample - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.6013 - val_accuracy: 0.8250\nEpoch 6/10\n25000/25000 [==============================] - 6s 252us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.6519 - val_accuracy: 0.8269\nEpoch 7/10\n25000/25000 [==============================] - 6s 253us/sample - loss: 8.5006e-04 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.8286\nEpoch 8/10\n25000/25000 [==============================] - 7s 273us/sample - loss: 4.6341e-04 - accuracy: 1.0000 - val_loss: 0.7299 - val_accuracy: 0.8280\nEpoch 9/10\n25000/25000 [==============================] - 7s 263us/sample - loss: 2.6600e-04 - accuracy: 1.0000 - val_loss: 0.7658 - val_accuracy: 0.8300\nEpoch 10/10\n25000/25000 [==============================] - 6s 260us/sample - loss: 1.5968e-04 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.8286\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(testing_padded, testing_labels_final)","execution_count":18,"outputs":[{"output_type":"stream","text":"25000/25000 [==============================] - 2s 77us/sample - loss: 0.8035 - accuracy: 0.8286\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Test accuracy:', score[1])","execution_count":19,"outputs":[{"output_type":"stream","text":"Test accuracy: 0.82864\n","name":"stdout"}]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}